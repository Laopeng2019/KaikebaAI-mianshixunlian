
# 第二天

## 1, 逻辑回归相比线性回归，有何异同？
![image](https://github.com/Laopeng2019/KaikebaAI-mianshixunlian/blob/master/%E5%BC%80%E8%AF%BE%E5%90%A7AI%E9%9D%A2%E8%AF%95%E8%AE%AD%E7%BB%83/image/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.jpg)

线性回归是在数据里面找到拟合线最合理反映两者之间的关系，所以是基于两者或者多者之间具有**线性**关系的假设进行的。

![image](https://github.com/Laopeng2019/KaikebaAI-mianshixunlian/blob/master/%E5%BC%80%E8%AF%BE%E5%90%A7AI%E9%9D%A2%E8%AF%95%E8%AE%AD%E7%BB%83/image/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.jpg)

逻辑回归是用来预测发生某种情况的概率有多大，以考试为例，在得到了原始数据的情况下，分两类：及格/不及格
>因此线性回归用于预测的范围比较广，而逻辑回归预测范围为[0,1]




## 2, 回归问题常用的性能度量指标
### 均方误差
是反映估计值与被估计量之间差异程度的度量
$$
    {\text{MSE}} = \cfrac {\text{SSE}}2 = \cfrac{1}{n} \sum_{i=1}^m (f(x_i)-y_i)^2
$$

### RMSE均方根误差
观测值与真值偏差的平方和与观测次数m比值的平方根，用来衡量观测值同真值之间的偏差
$$
    \text{RMSE}(x,h) = \sqrt{\cfrac{1}{m}\sum_{i=1}^m(h(x_i)-y_i)^2}
$$

### R平方
$$
    R^2 = 1-\cfrac{\text{SSE}}{\text{SST}} 

$$
$$
    \text{SST}=\sum_{i=1}^n(y_i-\overline{y} ) 
$$
$$
    \text{SSE} = \sum_{i=1}^m(f(x_i)-y_i)^2
$$

### 平均绝对误差（MAE）
$$
    \text{MAE}=\cfrac{1}{n}\sum_{i=0}^n(f(xi)-y_i)

$$

### F统计量(还不懂)




## 3, 分类问题常用的性能度量指标
分类问题通常有，二分类，多分类，多标签分类三种基本问题
二分类：将一个样本划分到两个类别的集合中，
多分类：将一个样本划分到多个类别的集合中，
多标签分类：将一个样本划分到多个类别的某几类集合中.

性能指标：
1，错误率与精度
2，准确率，召回率，F1值
在2，里面，二分类：
1. 错误率与精度
2. 准确率，召回率，F1值
$$
    \text{Pricision}=\cfrac{TP}{(TP+FP)} \\
    \text{Recall}=\cfrac{TP}{TP+FN}

$$


~~precision和recall是负相关的量，precision高recall不要太低，recall高precision也不要太低。~~(查资料过程看到的gp话)

由F1公式
$$
    \cfrac{2}{F1}=\cfrac{1}{P}+\cfrac{1}{R}
$$
可知
$$
    P\uparrow\Rightarrow \cfrac{1}{P}\downarrow \Rightarrow \cfrac{2}{\text{F1}} \downarrow\Rightarrow \text{F1} \uparrow
$$
或者
$$
    P\uparrow\Rightarrow \cfrac{1}{P}\downarrow \Rightarrow \cfrac{1}{R} \uparrow \Rightarrow R\downarrow   
$$
所以
>当准确率P增大时，如果召回率R不增大，F1就会提高。如果F1不变的情况下，R减小。

### ROC与AUC




## 4,逻辑回归的损失函数


## 5,逻辑回归处理多标签分类问题时，一般怎么做


## 6,写出全概率公式\&贝叶斯公式


## 7,朴素贝叶斯为什么“朴素naive”？


